# Migration vers Gemini 2.x

## ‚úÖ Checklist "Pr√™te pour D√©mo"

### 1. SDK Unifi√© Configur√©
- ‚úÖ Environment: `GOOGLE_CLOUD_LOCATION=global`
- ‚úÖ Vertex AI activ√© dans le projet GCP
- ‚úÖ Service Account avec permissions Vertex AI

### 2. Mod√®les Gemini 2.x

#### **gemini-2.0-flash-exp** (Production/D√©mo)
- **Usage**: NLU en temps r√©el, extraction √©v√©nements/√©motions
- **Avantages**: 
  - Rapide et cost-effective
  - Parfait pour d√©mo/prod
  - Disponible en `global` endpoint
- **Configuration actuelle**: Par d√©faut dans `GEMINI_MODEL`

#### **gemini-2.5-pro** (Synth√®se Hebdomadaire)
- **Usage**: Raisonnement avanc√© pour rapports hebdomadaires
- **Avantages**:
  - Meilleure compr√©hension contextuelle
  - Analyses plus nuanc√©es
  - Recommandations th√©rapeutiques
- **Configuration**: Set `GEMINI_MODEL=gemini-2.5-pro` pour la synth√®se

### 3. Migration depuis Gemini 1.5
```bash
# ‚ùå D√©pr√©ci√© (s√©rie 1.5)
gemini-1.5-pro
gemini-1.5-flash

# ‚úÖ Recommand√© (s√©rie 2.x)
gemini-2.0-flash-exp    # Remplace 1.5-flash
gemini-2.5-pro          # Remplace 1.5-pro (upgrade)
```

### 4. Configuration R√©gion/Endpoint

```bash
# ‚ùå Ancien (r√©gional, limit√©)
REGION=europe-west1
aiplatform.init(location="europe-west1")

# ‚úÖ Nouveau (global, Gemini 2.x)
GOOGLE_CLOUD_LOCATION=global
aiplatform.init(location="global")
```

## üöÄ Pour la D√©mo Hackathon

### Setup Actuel
```python
# main.py
GEMINI_MODEL = os.environ.get("GEMINI_MODEL", "gemini-2.0-flash-exp")
GEMINI_LOCATION = os.environ.get("GOOGLE_CLOUD_LOCATION", "global")

aiplatform.init(project=PROJECT_ID, location=GEMINI_LOCATION)
model = GenerativeModel(GEMINI_MODEL)
```

### Variables d'Environnement (Cloud Run Job)
```bash
GEMINI_MODEL=gemini-2.0-flash-exp
GOOGLE_CLOUD_LOCATION=global
```

### Test du Mod√®le
```bash
# Test avec gemini-2.0-flash (par d√©faut)
gcloud run jobs execute mj-weekly-pipeline \
  --region=europe-west1 \
  --args=2025-W42

# Test avec gemini-2.5-pro (synth√®se avanc√©e)
gcloud run jobs execute mj-weekly-pipeline \
  --region=europe-west1 \
  --update-env-vars GEMINI_MODEL=gemini-2.5-pro \
  --args=2025-W42
```

## üìä Comparaison Mod√®les

| Mod√®le | Usage | Vitesse | Co√ªt | Qualit√© |
|--------|-------|---------|------|---------|
| `gemini-2.0-flash-exp` | NLU temps r√©el | ‚ö°‚ö°‚ö° | üí∞ | ‚≠ê‚≠ê‚≠ê |
| `gemini-2.5-pro` | Synth√®se hebdo | ‚ö°‚ö° | üí∞üí∞ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

## üîÆ Roadmap Live API (Post-Hackathon)

Pour du bouton-parler en temps r√©el :
```python
# Future: Gemini 2.0 Flash Live API
from vertexai.preview.generative_models import GenerativeModel

model = GenerativeModel(
    "gemini-2.0-flash-live",  # Live streaming
    generation_config={
        "stream": True,
        "audio_enabled": True
    }
)
```

## ‚úÖ √âtat de Conformit√©

- ‚úÖ Mod√®les Gemini 2.x officiels (IDs Vertex/Gemini API)
- ‚úÖ Endpoint `global` configur√©
- ‚úÖ Migration compl√®te depuis s√©rie 1.5 (d√©pr√©ci√©e)
- ‚úÖ Pr√™t pour d√©mo hackathon
- ‚è≥ Live API (planning post-V1)

## üìù Notes de Migration

**Changements effectu√©s:**
1. `gemini-1.5-pro` ‚Üí `gemini-2.0-flash-exp` (d√©faut)
2. `us-central1` ‚Üí `global` (location)
3. Ajout variables `GEMINI_MODEL` et `GOOGLE_CLOUD_LOCATION`
4. Scripts `deploy.sh` mis √† jour avec nouvelles env vars

**Aucun breaking change** dans l'API - juste changement de model ID.
