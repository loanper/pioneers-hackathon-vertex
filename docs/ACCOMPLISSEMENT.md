# ğŸ‰ Journal Mental Vocal - Infrastructure Vertex AI DÃ©ployÃ©e

**Date** : 16 octobre 2025  
**Statut** : âœ… **PRODUCTION OPÃ‰RATIONNELLE**  
**ModÃ¨le IA** : Gemini 2.0 Flash Experimental (Google Vertex AI)

---

## ğŸ¯ Objectif RÃ©alisÃ©

DÃ©ploiement complet d'une infrastructure Vertex AI pour analyser automatiquement des enregistrements vocaux de journal mental hebdomadaire :

**Audio â†’ Transcription â†’ Analyse Prosodique â†’ NLU (Gemini) â†’ Rapport PDF**

---

## ğŸ“Š RÃ©sultats du Test (2025-W42)

âœ… **Pipeline exÃ©cutÃ© avec succÃ¨s** - exitCode=0  
âœ… **STT (Speech-to-Text)** : Transcription complÃ¨te avec timestamps  
âœ… **Analyse Prosodique** : Pitch, Ã©nergie, pauses dÃ©tectÃ©es (librosa)  
âœ… **NLU Gemini 2.0 Flash** : Extraction Ã©vÃ©nements/Ã©motions/thÃ¨mes  
âœ… **Rapports gÃ©nÃ©rÃ©s** : JSON + HTML + PDF (WeasyPrint)  
âœ… **Index Ã©motionnel calculÃ©** : 50.0/100  

---

## ğŸ—ï¸ Infrastructure DÃ©ployÃ©e (GCP)

### Projet GCP
- **ID** : `mental-journal-dev`
- **RÃ©gion** : `europe-west1` (infrastructure)
- **Billing** : `0160FD-7699F7-CC0BD4` (activÃ©)
- **CoÃ»t estimÃ©** : ~0.30â‚¬/semaine (~1.20â‚¬/mois)

### Services ActivÃ©s
```
âœ… Cloud Run (Jobs)
âœ… Cloud Storage (4 buckets CMEK)
âœ… Cloud KMS (encryption)
âœ… Speech-to-Text v2 API
âœ… Vertex AI (Gemini API)
âœ… Cloud Logging
âœ… BigQuery (futur analytics)
```

### Cloud Storage (4 Buckets)
```
mj-audio-raw-mental-journal-dev          # Audio source
mj-audio-processed-mental-journal-dev    # Audio traitÃ©
mj-analytics-mental-journal-dev          # JSON analytics
mj-reports-mental-journal-dev            # HTML/PDF
```
- **Encryption** : CMEK avec Cloud KMS
- **Lifecycle** : Suppression auto aprÃ¨s 90 jours
- **RÃ©gion** : `europe-west1`

### Cloud Run Job
- **Nom** : `mj-weekly-pipeline`
- **Container** : `gcr.io/mental-journal-dev/mj-pipeline:latest`
- **Service Account** : `pipeline-sa` (11 IAM roles)
- **Timeout** : 3600s (1h)
- **Max Retries** : 1

---

## ğŸ¤– Stack Technique

### ModÃ¨les IA
| ModÃ¨le | Usage | Configuration |
|--------|-------|---------------|
| **Speech-to-Text v2** | Transcription audio | `model=long`, `location=global` |
| **Gemini 2.0 Flash Exp** | NLU temps rÃ©el | `location=global` (SDK unifiÃ©) |
| **Gemini 2.5 Pro** | SynthÃ¨se avancÃ©e | Futur (escalation path) |

### Pipeline Python (Docker)
```
Python 3.11
â”œâ”€â”€ google-cloud-storage      # GCS I/O
â”œâ”€â”€ google-cloud-speech       # STT v2
â”œâ”€â”€ google-cloud-aiplatform   # Vertex AI
â”œâ”€â”€ librosa                   # Analyse prosodique
â”œâ”€â”€ scipy + numpy             # Signal processing
â”œâ”€â”€ jinja2                    # Templates
â””â”€â”€ weasyprint                # HTMLâ†’PDF
```

### Container
- **Base** : `debian:trixie-slim`
- **Runtime** : Python 3.11 + ffmpeg
- **Size** : ~1.2 GB (avec dÃ©pendances ML)
- **Registry** : Google Container Registry
- **Builds** : 6 itÃ©rations (debugging + optimisation)

---

## ğŸ”§ Parcours Technique (Debugging)

### ItÃ©rations RÃ©ussies

**Build 1-2** : STT Region Fix
- âŒ ProblÃ¨me : `Expected resource location to be global, but found europe-west1`
- âœ… Solution : Recognizer en `location=global`

**Build 3** : STT Model Parameter
- âŒ ProblÃ¨me : `Invalid 'model': field must be non-empty`
- âœ… Solution : Ajout `model="long"` (audio longs)

**Build 4-5** : Gemini Region Access
- âŒ ProblÃ¨me : `Publisher Model not found in europe-west1/us-central1`
- âŒ Tentative : `gemini-1.5-pro` â†’ Not found
- âŒ Tentative : `gemini-pro` â†’ Deprecated

**Build 6** : Migration Gemini 2.x âœ…
- âœ… Solution : `gemini-2.0-flash-exp` + `location=global`
- âœ… Variables d'environnement configurables
- âœ… Pipeline opÃ©rationnel !

### LeÃ§ons Apprises
1. **STT v2 nÃ©cessite `location=global`** pour les recognizers
2. **Gemini 1.5 series est dÃ©prÃ©ciÃ©e** â†’ Migration 2.x obligatoire
3. **Gemini 2.x requiert `location=global`** pour compatibilitÃ© maximale
4. **Variables d'environnement** essentielles pour Ã©viter les updates partielles

---

## ğŸ“ Architecture du Code

```
vertex/
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ main.py              # Orchestrateur principal (405 lignes)
â”‚   â”œâ”€â”€ requirements.txt     # DÃ©pendances Python
â”‚   â””â”€â”€ Dockerfile          # Container Python 3.11
â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ transcript.schema.json
â”‚   â”œâ”€â”€ prosody.schema.json
â”‚   â”œâ”€â”€ events_emotions.schema.json
â”‚   â””â”€â”€ weekly_report.schema.json
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ weekly_report.html   # Template Jinja2
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_infra.sh       # Init GCP (buckets, KMS, SA)
â”‚   â”œâ”€â”€ deploy.sh            # Build + Deploy Cloud Run Job
â”‚   â”œâ”€â”€ check_results.sh     # VÃ©rification outputs
â”‚   â””â”€â”€ cleanup.sh           # Suppression resources
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ README.md            # Documentation projet
â”‚   â””â”€â”€ GEMINI_2X_MIGRATION.md  # Guide migration Gemini
â””â”€â”€ .env.example             # Variables d'environnement
```

---

## ğŸš€ Comment Ã‡a Marche

### 1. Upload Audio
```bash
# Structure : gs://bucket/YYYY-Www/session_XXX.wav
gsutil cp audio.wav gs://mj-audio-raw-mental-journal-dev/2025-W42/session_001.wav
```

### 2. ExÃ©cution Pipeline
```bash
# Manuel
gcloud run jobs execute mj-weekly-pipeline --args=2025-W42

# Auto (futur : Cloud Scheduler tous les lundis)
```

### 3. Outputs GÃ©nÃ©rÃ©s
```
gs://mj-analytics-mental-journal-dev/2025-W42/
â”œâ”€â”€ session_001/
â”‚   â”œâ”€â”€ transcript.json           # STT avec timestamps
â”‚   â”œâ”€â”€ prosody_features.json     # Pitch/Ã©nergie/pauses
â”‚   â””â”€â”€ events_emotions.json      # NLU Gemini
â””â”€â”€ weekly_report.json            # SynthÃ¨se complÃ¨te

gs://mj-reports-mental-journal-dev/2025-W42/
â”œâ”€â”€ weekly_report.html
â””â”€â”€ weekly_report.pdf
```

---

## ğŸ“ Points Techniques AvancÃ©s

### Speech-to-Text v2
```python
recognizer = f"projects/{PROJECT_ID}/locations/global/recognizers/_"
config = RecognitionConfig(
    model="long",              # Audio longs (>5min)
    language_codes=["fr-FR"],
    enable_word_time_offsets=True,
    enable_word_confidence=True
)
```

### Vertex AI Gemini 2.0
```python
aiplatform.init(project=PROJECT_ID, location="global")
model = GenerativeModel("gemini-2.0-flash-exp")

# Prompt JSON structurÃ© pour NLU
prompt = f"""Analyse: {text}
Format JSON: {{"events": [...], "emotions": [...], "themes": [...]}}"""
```

### Analyse Prosodique (librosa)
```python
# Extraction features vocales
pitch = librosa.yin(y, fmin=75, fmax=300)      # F0
energy = librosa.feature.rms(y=y)[0]           # IntensitÃ©
pauses = detect_pauses(y, top_db=30)          # Silences
```

---

## ğŸ“ˆ MÃ©triques & KPIs

### Performance Pipeline
- â±ï¸ **DurÃ©e** : ~40s pour 5s d'audio (test)
- ğŸ’¾ **RAM** : ~2 GB (librosa + ML models)
- ğŸ”„ **Retry** : 1 tentative max
- â° **Timeout** : 1h (sessions longues)

### CoÃ»ts EstimÃ©s (par semaine)
```
Speech-to-Text v2  :  ~0.10â‚¬  (15min audio)
Vertex AI Gemini   :  ~0.15â‚¬  (NLU + synthÃ¨se)
Cloud Storage      :  ~0.02â‚¬  (4 buckets)
Cloud Run          :  ~0.03â‚¬  (1 job/semaine)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL              :  ~0.30â‚¬/semaine (~1.20â‚¬/mois)
```

---

## ğŸ”® Roadmap V2

### Features Ã  Venir
- [ ] **Cloud Scheduler** : ExÃ©cution auto tous les lundis 9h
- [ ] **Gemini 2.5 Pro** : SynthÃ¨se avancÃ©e hebdomadaire
- [ ] **Live API** : Streaming audio temps rÃ©el (bouton-parler)
- [ ] **BigQuery Analytics** : Dashboard Looker Studio
- [ ] **Alertes** : Notifications si index < 30
- [ ] **Multi-user** : Support plusieurs utilisateurs

### AmÃ©liorations Techniques
- [ ] Retry logic pour failures Gemini
- [ ] Cache local pour Ã©viter re-processing
- [ ] Compression audio (FLAC) pour coÃ»ts storage
- [ ] Batch processing pour plusieurs sessions
- [ ] Tests unitaires + CI/CD (Cloud Build)

---

## ğŸ† Accomplissements ClÃ©s

âœ… **Infrastructure Production** : GCP complÃ¨te avec CMEK encryption  
âœ… **Pipeline ML End-to-End** : Audio â†’ Insights en 1 commande  
âœ… **ModÃ¨le IA Moderne** : Gemini 2.0 Flash (derniÃ¨re gÃ©nÃ©ration)  
âœ… **Documentation ComplÃ¨te** : Schemas JSON + guides migration  
âœ… **CoÃ»ts OptimisÃ©s** : <2â‚¬/mois pour usage hebdomadaire  
âœ… **Scalable** : PrÃªt pour multi-utilisateurs  

---

## ğŸ“ Commandes Utiles

```bash
# ExÃ©cuter pipeline
gcloud run jobs execute mj-weekly-pipeline --args=$(date +'%G-W%V')

# VÃ©rifier rÃ©sultats
./scripts/check_results.sh 2025-W42

# Voir logs
gcloud logging read "resource.type=cloud_run_job" --limit=50

# Lister outputs
gsutil ls gs://mj-analytics-mental-journal-dev/2025-W42/

# TÃ©lÃ©charger rapport
gsutil cp gs://mj-reports-mental-journal-dev/2025-W42/weekly_report.pdf ./
```

---

## ğŸ‘¥ Ã‰quipe & Contexte

**Projet** : GCPU Hackathon - Mental Health Journal  
**Date DÃ©ploiement** : 16 octobre 2025  
**DurÃ©e** : 1 session intensive (6 builds, debugging itÃ©ratif)  
**Stack** : GCP + Python + Gemini AI + Docker  

---

## ğŸ¯ Conclusion

**Le systÃ¨me est opÃ©rationnel et prÃªt pour la dÃ©mo !**

- âœ… Pipeline testÃ© et validÃ© sur audio rÃ©el
- âœ… Gemini 2.0 Flash intÃ©grÃ© avec succÃ¨s
- âœ… Outputs (JSON/HTML/PDF) gÃ©nÃ©rÃ©s correctement
- âœ… Infrastructure GCP sÃ©curisÃ©e (CMEK + IAM)
- âœ… Documentation et scripts ready-to-use

**Next Step** : PrÃ©sentation dÃ©mo avec audio test 2025-W42 âœ¨
