# ğŸ­ Module d'Analyse Prosodique Ã‰motionnelle - Guide d'IntÃ©gration

## âœ… Tests ValidÃ©s

```bash
cd pipeline
python test_final.py

# Ou avec ton propre fichier audio
python test_final.py chemin/vers/audio.wav
```

**RÃ©sultats des tests:**
- âœ… Analyse batch (fichier complet) : OK
- âœ… Analyse streaming (chunk par chunk) : OK
- âœ… DÃ©tection de 8 Ã©motions : OK
- âœ… Confiance scores : OK

---

## ğŸ“¦ Fichiers du Module

```
pioneers-hackathon-vertex/
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ prosody_emotion_analyzer.py    â† Module principal (TOUT est lÃ )
â”‚   â”œâ”€â”€ test_final.py                  â† Test complet
â”‚   â””â”€â”€ example_integration_gemini_live.py  â† Exemple pour Gemini Live
â””â”€â”€ api/routers/
    â””â”€â”€ live_prosody.py                â† WebSocket endpoint (optionnel)
```

**1 SEUL fichier Ã  importer:** `prosody_emotion_analyzer.py`

---

## ğŸš€ IntÃ©gration - Ami #1 (Gemini Live API)

### Code minimal (3 lignes)

```python
from prosody_emotion_analyzer import StreamingProsodyAnalyzer

# 1. CrÃ©er l'analyzer (une fois au dÃ©but)
analyzer = StreamingProsodyAnalyzer(sample_rate=16000)

# 2. Dans ta boucle Gemini Live qui reÃ§oit l'audio
result = analyzer.add_audio_chunk(audio_chunk)  # audio_chunk = numpy array

# 3. Si rÃ©sultat disponible (toutes les 3 secondes)
if result:
    emotion = result["dominant_emotion"]["label"]
    confidence = result["dominant_emotion"]["confidence"]
    # â†’ Envoyer Ã  l'ami #2 via webhook
```

### Format de sortie

```json
{
  "dominant_emotion": {
    "label": "stress",
    "confidence": 0.25
  },
  "all_emotions": [
    {"label": "stress", "confidence": 0.25},
    {"label": "peur", "confidence": 0.21},
    {"label": "neutre", "confidence": 0.18}
  ],
  "vocal_characteristics": {
    "pitch_level": "high",
    "pitch_variation": "very_expressive",
    "energy_level": "high",
    "speaking_speed": "slow"
  }
}
```

---

## ğŸ”— IntÃ©gration - Ami #2 (n8n + ElevenLabs)

### Webhook n8n (JavaScript)

```javascript
// Recevoir de l'ami #1
const emotion = $json.dominant_emotion.label;
const confidence = $json.dominant_emotion.confidence;

// Mapper vers paramÃ¨tres de voix ElevenLabs
const emotionToVoice = {
  "stress": { 
    stability: 0.3,        // Voix instable
    similarity_boost: 0.8,  // Haute expression
    style: 1.0             // Style accentuÃ©
  },
  "joie": { 
    stability: 0.5, 
    similarity_boost: 0.9,
    style: 0.8 
  },
  "tristesse": { 
    stability: 0.7,        // Voix stable
    similarity_boost: 0.4,  // Basse expression
    style: 0.3 
  },
  "colÃ¨re": { 
    stability: 0.2, 
    similarity_boost: 1.0,
    style: 1.0 
  },
  "calme": { 
    stability: 0.9, 
    similarity_boost: 0.6,
    style: 0.2 
  },
  "peur": { 
    stability: 0.4, 
    similarity_boost: 0.7,
    style: 0.7 
  },
  "excitation": { 
    stability: 0.3, 
    similarity_boost: 0.95,
    style: 0.9 
  },
  "neutre": { 
    stability: 0.5, 
    similarity_boost: 0.75,
    style: 0.5 
  }
};

// Utiliser les paramÃ¨tres
const voiceSettings = emotionToVoice[emotion] || emotionToVoice["neutre"];

return {
  text: $json.llm_response,  // RÃ©ponse de Gemini
  voice_settings: voiceSettings
};
```

---

## ğŸ“Š Ã‰motions DÃ©tectÃ©es

| Ã‰motion | CaractÃ©ristiques | Use Case |
|---------|------------------|----------|
| **stress** | Pitch Ã©levÃ©, variation haute, rapide | Personne anxieuse/stressÃ©e |
| **joie** | Pitch moyen-haut, Ã©nergique | Personne heureuse |
| **tristesse** | Pitch bas, lent, peu d'Ã©nergie | Personne triste |
| **colÃ¨re** | Pitch trÃ¨s haut, trÃ¨s Ã©nergique | Personne en colÃ¨re |
| **calme** | Pitch stable, pauses rÃ©guliÃ¨res | Personne dÃ©tendue |
| **peur** | Pitch Ã©levÃ©, Ã©nergie moyenne | Personne effrayÃ©e |
| **excitation** | Pitch moyen-haut, trÃ¨s Ã©nergique | Personne excitÃ©e |
| **neutre** | CaractÃ©ristiques moyennes | Ã‰tat neutre |

---

## ğŸ§ª Tester en Local (sans dÃ©ployer)

```bash
# Test avec le fichier d'exemple
cd /home/loan/hackathon/pioneers-hackathon-vertex/pipeline
python test_final.py

# Test avec ton propre fichier
python test_final.py /chemin/vers/ton_audio.wav
```

**Output attendu:**
```
âœ… ChargÃ©: 96.0 secondes

ğŸ­ Ã‰motion dominante: stress
   Confiance: 20.4%

ğŸ“Š Top 5 Ã©motions:
   1. stress       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     20.4%
   2. peur         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      18.4%
   3. neutre       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      18.4%

ğŸ“ˆ RÃ©sumÃ© du streaming:
   Analyses effectuÃ©es: 94
   Ã‰motion globale: stress (57% du temps)
```

---

## ğŸ”„ Flow Complet

```
User parle ğŸ—£ï¸
    â†“
Gemini Live API (audio stream)
    â†“
[Ami #1] prosody_emotion_analyzer.py
    â†“ {"dominant_emotion": {"label": "stress", "confidence": 0.25}}
[Ami #2] n8n webhook â†’ mapper emotion â†’ voice settings
    â†“
ElevenLabs API
    â†“
ğŸ”Š RÃ©ponse vocale avec Ã©motion adaptÃ©e
```

---

## ğŸ’¡ Notes Importantes

1. **Sample Rate:** L'audio doit Ãªtre Ã  **16kHz** (le module le gÃ¨re automatiquement avec librosa)
2. **Format audio:** numpy array float32
3. **FrÃ©quence d'analyse:** Toutes les 3 secondes avec fenÃªtre glissante de 1 seconde
4. **DÃ©pendances:** `librosa soundfile numpy scipy` (dÃ©jÃ  dans `requirements.txt`)

---

## âœ… Checklist d'IntÃ©gration

### Ami #1 (Gemini Live):
- [ ] Import `from prosody_emotion_analyzer import StreamingProsodyAnalyzer`
- [ ] CrÃ©er analyzer au dÃ©but de session
- [ ] Appeler `analyzer.add_audio_chunk()` pour chaque chunk reÃ§u
- [ ] Envoyer rÃ©sultat Ã  n8n quand disponible

### Ami #2 (n8n):
- [ ] CrÃ©er webhook pour recevoir Ã©motions
- [ ] ImplÃ©menter le mapping emotion â†’ voice settings
- [ ] Tester avec des Ã©motions simulÃ©es
- [ ] IntÃ©grer avec ElevenLabs API

---

**Module testÃ© et validÃ© âœ…**  
**PrÃªt pour le hackathon ğŸš€**
